{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ztHNEiPhbahiFSiklAM1Tm9lQO8b1Z-Y","timestamp":1669981000544},{"file_id":"1xrvG7SL9bEdo_GDTxdCXn6z3CMTInkD1","timestamp":1611157681407}],"authorship_tag":"ABX9TyPh2K0eNeIS/u3KZuPOlu5V"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Aoa6pZPX7Y-K"},"source":["# Query the Arxiv Preprint Server\n","\n","This **Notebook-as-Tool** allows you to:\n","\n","1. query the preprint server arxiv.org and retrieve results as csv. The query routine retrieves data on four levels: (a) title field, (b) abstract field, (c) all fields and (d) without search scope.\n","2. specify the number of reults to retrieve and the sort order of the results.\n","\n","For running or adapting this Colab Notebook you need to create a copy in you Google drive: **File → Save a copy in Drive**. I will be stored in a folder ```Colab Notebooks```. Open this file with Google Colab and run the cells consecutively by pressing the **Play** button or pushing **shift+enter**.\n","\n","**Important notes:**\n","- Code is hidden in the background of Colab forms. For viewing and editing the code **double click** cell or select  **View → Show/hide code**\n","- Data will be stored in Google Drive in the folder ```Colab Data```. A connection to your drive will be authenticated when running setup code cells. This is temporary and only your current notebook will be conncted to your drive. The connection will be revoked when the notebook is terminated or by selecting **Runtime → Factory reset runtime**.\n","\n","\n","**Credits:** This notebook was written by Marcus Burkhardt and makes use of the arxiv API wrapper."]},{"cell_type":"code","metadata":{"id":"oLTj7lsf8MI4","cellView":"form"},"source":["#@title Setup 1: Mount Google Drive for Loading and Storing Data\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L-brkUZx7xwc","cellView":"form"},"source":["#@title Setup 2: Install and Load Required Libraries and Run Setup Procedures\n","\n","# Install Libraries\n","try:\n","  import feedparser\n","  pass\n","except:\n","  !pip install feedparser\n","  import feedparser\n","  pass\n","\n","# Import Libaries\n","import os\n","import time\n","import pandas as pd\n","from datetime import datetime\n","from tqdm.notebook import tqdm\n","import requests\n","\n","# Defining path variable for data path\n","data_path = os.path.join(\"gdrive\", \"MyDrive\", \"Colab_Data\", \"Data\", \"Arxiv\")\n","if not os.path.isdir(data_path):\n","  os.makedirs(data_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IgH6JowL0iYB","cellView":"form","executionInfo":{"status":"ok","timestamp":1724857148356,"user_tz":-120,"elapsed":233,"user":{"displayName":"Marcus Burkhardt","userId":"16009817661636280740"}}},"source":["#@title Setup 3: Definition of Core and Support Functions Used by the Tool(s)\n","\n","def query_arxiv(query, max_results, search_scope=None, sort_by='relevance', sort_order='ascending'):\n","    print(f'Start querying arxiv for term: {query} (scope: {search_scope})')\n","    per_page = 10000\n","    if max_results < per_page:\n","        per_page = max_results\n","    start = 0\n","    more = True\n","    results = []\n","    while more:\n","        if search_scope is None:\n","            url = f\"https://export.arxiv.org/api/query?search_query={query}&max_results={per_page}&start={start}&sortBy={sort_by}&sortOrder={sort_order}\"\n","        else:\n","            url = f\"https://export.arxiv.org/api/query?search_query={search_scope}:{query}&max_results={per_page}&start={start}&sortBy={sort_by}&sortOrder={sort_order}\"\n","        if start == 0:\n","            print(f'Initial query for first {per_page} results: {url}')\n","        print('.', end='')\n","        resp = requests.get(url)\n","        resp = feedparser.parse(resp.text)\n","        items = resp['entries']\n","        start += per_page\n","        if len(items) > 0:\n","            if len(results) + len(items) > max_results:\n","                results += items[:max_results - len(results)]\n","                more = False\n","                print('')\n","            else:\n","                results += items\n","        else:\n","            more = False\n","            print('')\n","    results = pd.json_normalize(results)\n","    return results\n","\n","def query(q, max_results=1000, max_results_by_scope=False, sort_by='relevance', sort_order='ascending'):\n","    qti = query_arxiv(q, search_scope='ti', max_results=max_results, sort_by=sort_by, sort_order=sort_order)\n","    qtiUnique = qti.copy()\n","    qtiUnique['[Result Type]'] = 'title'\n","\n","    results = qtiUnique.copy()[:max_results]\n","    if not max_results_by_scope and len(results) >= max_results:\n","        return results[:max_results]\n","\n","    qabs = query_arxiv(q, search_scope='abs', max_results=max_results, sort_by=sort_by, sort_order=sort_order)\n","    if len(qtiUnique) > 0 and len(qabs) > 0:\n","        qabsUnique = qabs[~qabs['id'].isin(qti['id'].tolist())].copy()\n","    else:\n","        qabsUnique = qabs.copy()\n","    qabsUnique['[Result Type]'] = 'abstract'\n","\n","    qabsUnique = qabsUnique[:max_results]\n","    results = pd.concat([results, qabsUnique])\n","    if not max_results_by_scope and len(results) >= max_results:\n","        return results[:max_results]\n","\n","    qall = query_arxiv(q, search_scope='all', max_results=max_results, sort_by=sort_by, sort_order=sort_order)\n","    qtmp = pd.concat([qtiUnique, qabsUnique])\n","    if len(qtmp) > 0 and len(qall) > 0:\n","        qallUnique = qall[(~qall['id'].isin(qtmp['id'].tolist()))].copy()\n","    else:\n","        qallUnique = qall.copy()\n","    qallUnique['[Result Type]'] = 'all'\n","    qallUnique = qallUnique[:max_results]\n","    results = pd.concat([results, qallUnique])\n","    if not max_results_by_scope and len(results) >= max_results:\n","        return results[:max_results]\n","\n","    qnoscope = query_arxiv(q, search_scope=None, max_results=max_results, sort_by=sort_by, sort_order=sort_order)\n","    qtmp = pd.concat([qtiUnique, qabsUnique, qallUnique])\n","    if len(qtmp) > 0 and len(qnoscope) > 0:\n","        qnoscopeUnique = qnoscope[~qnoscope['id'].isin(qtmp['id'].tolist())].copy()\n","    else:\n","        qnoscopeUnique = qnoscope.copy()\n","    qnoscopeUnique['[Result Type]'] = 'No Scope'\n","    qnoscopeUnique = qnoscopeUnique[:max_results]\n","\n","    results = pd.concat([results, qnoscopeUnique])\n","    if not max_results_by_scope and len(results) >= max_results:\n","        return results[:max_results]\n","\n","    return results"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"GPgvi0yA7Utg","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724858072334,"user_tz":-120,"elapsed":800125,"user":{"displayName":"Marcus Burkhardt","userId":"16009817661636280740"}},"outputId":"c7c0166e-c147-40b2-a0c8-593bd1daac5a"},"source":["#@title Query arxiv.org\n","#@markdown\n","#@markdown ____________\n","#@markdown ### Specify the search query\n","query_term = '' #@param {type:\"string\"}\n","#@markdown >**Please note:** The entered search term is queried iteratively using different search scopes: title, abstract, and all. These scopes are provided by the API. In the last iteration the search term is queried without a scope. If the same article is retrieved for multiple scopes only the first is retained in the results set. This is reflected in the column [Result Type] which is added by the script and not archix metadata.\n","#@markdown ____________\n","#@markdown ### Specify the number of results to retrieve\n","max_results = 1000 # @param {type:\"integer\"}\n","max_results_by_scope = False # @param {type:\"boolean\"}\n","#@markdown >**Please note:** If max_results_by_scope is checked, max_results applies to each search scope (title, abstract, all, and no scope) separately, i.e. the total amount of results might be higher than the set maximus. If unchecked, the chosen number of max_results is the total maximum.\n","#@markdown ____________\n","#@markdown ### Specify the order of results\n","sort_by = 'relevance' # @param [\"relevance\", \"lastUpdatedDate\", \"submittedDate\"] {allow-input: false}\n","sort_order = 'descending' # @param [\"ascending\", \"descending\"] {allow-input: false}\n","#@markdown >**Please note:** Users can query arxiv by relevance, the date an article was submitted and the date it was last updated. Results can be sorted in ascending or descending order.\n","#@markdown ____________\n","\n","\n","print('Run query...')\n","results = query(query_term, max_results, max_results_by_scope, sort_by, sort_order)\n","outfile_name = f\"{query_term}_{len(results)}_results_SEARCH_PARAMS_max_results_{max_results}_max_results_by_scope_{max_results_by_scope}_sortBy_{sort_by}_sortOrder_{sort_order}_QUERY_TIME_{datetime.now()}.csv\" # could be added as a form field.\n","outfile = os.path.join(data_path, outfile_name)\n","print()\n","print(f\"In total {len(results)} have been retrieved.\")\n","results[\"[Query Term]\"] = query_term\n","if len(results) > 0:\n","    results[\"[Comment]\"] = \"\"\n","    cols = [\"id\", \"[Result Type]\", \"[Query Term]\", \"[Comment]\",\n","            \"author\", \"authors\", \"published\", \"updated\", \"title\",\n","            \"summary\", \"arxiv_comment\", \"links\", \"tags\",\n","            \"title_detail.type\", \"title_detail.language\",\n","            \"title_detail.base\", \"title_detail.value\",\n","            \"summary_detail.type\", \"summary_detail.language\",\n","            \"summary_detail.base\", \"summary_detail.value\",\n","            \"author_detail.name\", \"arxiv_primary_category.term\",\n","            \"arxiv_primary_category.scheme\", \"arxiv_doi\",\n","            \"arxiv_journal_ref\", \"arxiv_affiliation\",\n","            \"guidislink\", \"link\", \"published_parsed\",\n","            \"updated_parsed\"]\n","    rcols = list(results.columns)\n","    if len([i for i in rcols if i not in cols]) > 0:\n","        print(f\"Retrieved results contain unknown columns: {[i for i in rcols if i not in cols]}.\")\n","        print(\"Script needs to be extended.\")\n","    results = results[[i for i in cols if i in rcols]]\n","    results.to_csv(outfile, sep='\\t', index=None)\n","\n","print(f'Results saved to {outfile}')\n","print('Done.')"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Run query...\n","Start querying arxiv for term: prompt (scope: ti)\n","Initial query for first 10000 results: https://export.arxiv.org/api/query?search_query=ti:prompt&max_results=10000&start=0&sortBy=relevance&sortOrder=descending\n","..\n","Start querying arxiv for term: prompt (scope: abs)\n","Initial query for first 10000 results: https://export.arxiv.org/api/query?search_query=abs:prompt&max_results=10000&start=0&sortBy=relevance&sortOrder=descending\n","...\n","Start querying arxiv for term: prompt (scope: all)\n","Initial query for first 10000 results: https://export.arxiv.org/api/query?search_query=all:prompt&max_results=10000&start=0&sortBy=relevance&sortOrder=descending\n","...\n","Start querying arxiv for term: prompt (scope: None)\n","Initial query for first 10000 results: https://export.arxiv.org/api/query?search_query=prompt&max_results=10000&start=0&sortBy=relevance&sortOrder=descending\n","...\n","\n","In total 17732 have been retrieved.\n","Results saved to gdrive/MyDrive/Colab_Data/Data/Arxiv/prompt_17732_results_SEARCH_PARAMS_max_results_25000_max_results_by_scope_False_sortBy_relevance_sortOrder_descending_QUERY_TIME_2024-08-28 15:14:29.181330.csv\n","Done.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"61KLtKKNogJh"},"execution_count":null,"outputs":[]}]}