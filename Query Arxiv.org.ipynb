{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ztHNEiPhbahiFSiklAM1Tm9lQO8b1Z-Y","timestamp":1669981000544},{"file_id":"1xrvG7SL9bEdo_GDTxdCXn6z3CMTInkD1","timestamp":1611157681407}],"toc_visible":true,"authorship_tag":"ABX9TyNJ9Sl8pQkx5aFREn3zNoS3"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Aoa6pZPX7Y-K"},"source":["# Query the Arxiv Preprint Server\n","\n","This **Notebook-as-Tool** allows you to:\n","\n","1.   query the preprint server arxiv.org and retrieve results as csv. The query routine retrieves data on three levels: (a) title field, (b) abstract field and (c) all fields. \n","\n","For running or adapting this Colab Notebook you need to create a copy in you Google drive: **File → Save a copy in Drive**. I will be stored in a folder ```Colab Notebooks```. Open this file with Google Colab and run the cells consecutively by pressing the **Play** button or pushing **shift+enter**.\n","\n","**Important notes:**\n","- Code is hidden in the background of Colab forms. For viewing and editing the code **double click** cell or select  **View → Show/hide code**\n","- Data will be stored in Google Drive in the folder ```Colab Data```. A connection to your drive will be authenticated when running setup code cells. This is temporary and only your current notebook will be conncted to your drive. The connection will be revoked when the notebook is terminated or by selecting **Runtime → Factory reset runtime**.\n","\n","\n","**Credits:** This notebook was written by Marcus Burkhardt and makes use of the arxiv API wrapper."]},{"cell_type":"code","metadata":{"id":"oLTj7lsf8MI4","cellView":"form"},"source":["#@title Setup 1: Mount Google Drive for Loading and Storing Data\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L-brkUZx7xwc","cellView":"form"},"source":["#@title Setup 2: Install and Load Required Libraries and Run Setup Procedures\n","\n","# Install Libraries\n","try: \n","  import arxiv\n","  import feedparser\n","  pass\n","except: \n","  !pip install arxiv\n","  import arxiv\n","  !pip install feedparser\n","  import feedparser\n","  pass\n","\n","# Import Libaries\n","import os\n","import time\n","import pandas as pd\n","from datetime import datetime\n","from tqdm.notebook import tqdm\n","import requests\n","\n","# Defining path variable for data path\n","data_path = os.path.join(\"gdrive\", \"MyDrive\", \"Colab_Data\", \"Data\", \"Arxiv\")\n","if not os.path.isdir(data_path):\n","  os.makedirs(data_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IgH6JowL0iYB","cellView":"form"},"source":["#@title Setup 3: Definition of Core and Support Functions Used by the Tool(s)\n","\n","def query_arxiv(query, max_results, search_scope='all', ):\n","    print(f'Start querying arxiv for term: {query} (scope: {search_scope})')\n","    max_results = 1000\n","    start = 0 - max_results\n","    more = True\n","    results = []\n","    while more:\n","        print('.', end='')\n","        start += max_results\n","        url = f\"https://export.arxiv.org/api/query?search_query={search_scope}:{query}&max_results={max_results}&start={start}\"\n","        resp = requests.get(url)\n","        resp = feedparser.parse(resp.text)\n","        items = resp['entries']\n","        if len(items) > 0:\n","            results += items\n","        else:\n","            more = False\n","            print('')\n","    results = pd.json_normalize(results)\n","    return results\n","\n","def query(q, max_results=1000):\n","    qti = query_arxiv(q, search_scope='ti', max_results=max_results)\n","    qabs = query_arxiv(q, search_scope='abs', max_results=max_results)\n","    qall = query_arxiv(q, search_scope='all', max_results=max_results)\n","    qtiUnique = qti.copy()\n","    qtiUnique['ResultType'] = 'title'\n","    \n","    if len(qtiUnique) > 0 and len(qabs) > 0:\n","        qabsUnique = qabs[~qabs['id'].isin(qti['id'].tolist())].copy()\n","        qabsUnique['ResultType'] = 'abstract'\n","    else:\n","        qabsUnique = qabs.copy()\n","        qabsUnique['ResultType'] = 'abstract' \n","    \n","    tmp = pd.concat([qtiUnique, qabsUnique])\n","    if len(tmp) > 0 and len(qall) > 0:\n","        qallUnique = qall[(~qall['id'].isin(qti['id'].tolist())) & (~qall['id'].isin(qabs['id'].tolist()))].copy()\n","    else:\n","        qallUnique = qall.copy()\n","    qallUnique['ResultType'] = 'all'\n","    results = pd.concat([qtiUnique, qabsUnique, qallUnique])\n","    return results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GPgvi0yA7Utg","cellView":"form"},"source":["#@title Query arxiv.org\n","query_term = \"consent\" #@param {type:\"string\"}\n","max_results = 10000 #@param {type:\"slider\", min:10, max:10000, step:10}\n","outfile_name = f\"{datetime.now()}_{query_term}_{max_results}.csv\" # could be added as a form field.\n","outfile = os.path.join(data_path, outfile_name)\n","print('Results will be stored at {}'.format('/'.join(outfile.split('/')[2:])))\n","\n","results = query(query_term, max_results)\n","print(f\"In total {len(results)} have been retrieved.\")\n","results[\"query term\"] = query_term\n","if len(results) > 0:\n","    results.to_csv(outfile, sep='\\t', index=None)\n","\n","print('Done.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"61KLtKKNogJh"},"execution_count":null,"outputs":[]}]}